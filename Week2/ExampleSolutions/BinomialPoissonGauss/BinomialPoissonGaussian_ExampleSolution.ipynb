{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binomial, Poisson and Gaussian distributions\n",
    "\n",
    "Python notebook for illustrating the Binomial, Poisson and Gaussian distributions and how they in certain limits converge towards each other (and in the end into the Gaussian). The notebook also illustrates simple fitting.\n",
    "\n",
    "## References:\n",
    "- Barlow: Chapter 3\n",
    "- Cowan: Chapter 2\n",
    "- Particle Data Group: __[\"Probability theorem and distributions\"](https://pdg.lbl.gov/2020/reviews/rpp2020-rev-probability.pdf)__\n",
    "\n",
    "## Author(s), contact(s), and dates:\n",
    "- Author: Troels C. Petersen (NBI)\n",
    "- Email:  petersen@nbi.dk\n",
    "- Date:   23rd of November 2021\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                     # Matlab like syntax for linear algebra and functions\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt                        # Plots and figures like you know them from Matlab\n",
    "from iminuit import Minuit                             # The actual fitting tool, better than scipy's\n",
    "import sys                                             # Modules to see files and folders in directories\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import binom, poisson, norm           # Functions from SciPy Stats..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `SciPy Stats` has nearly every conceivable function implemented:\n",
    "__[\"SciPy Stats functions\"](https://docs.scipy.org/doc/scipy/reference/stats.html)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../../External_Functions')\n",
    "from ExternalFunctions import Chi2Regression\n",
    "from ExternalFunctions import nice_string_output, add_text_to_ax   # Useful functions to print fit results on figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the parameters for the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General settings:\n",
    "r = np.random                       # Random generator\n",
    "r.seed(42)                          # Fixed order of random numbers\n",
    "\n",
    "save_plots = False\n",
    "verbose = True\n",
    "N_verbose = 10\n",
    "\n",
    "# Set plotting parameters:\n",
    "mpl.rcParams['font.size'] = 18      # Set the general plotting font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting PDFs:\n",
    "\n",
    "First, we want to have a look at the three PDFs (Binomial, Poisson, and Gaussian), and compare them given \"the same\" parameters. Of course we can't give the same input parameters, but at least we can require that they have the same mean and widths... Almost - one can not force the width of the Poisson to match that of the Binomial, once the mean is matched. The Gaussian will then have to choose between these two slightly different widths!\n",
    "\n",
    "### Problem parameters:\n",
    "* The Binomial PDF needs two parameters: Number of trials (n) and probability of succes (p).\n",
    "* The Poisson PDF needs one parameter:  The expected number (lambda - but in Python we write it \"Lambda\" or \"lamp\", as \"lambda\" is reserved!).\n",
    "* The Gaussian PDF needs two parameters: Mean (mu) and width (sigma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_binomial_pmf(x, n, p):\n",
    "    return binom.pmf(x, n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_poisson_pmf(x, lamb):\n",
    "    return poisson.pmf(x, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def func_gaussian_pdf(x, mu, sigma) :\n",
    "    return norm.pdf(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of outcome:\n",
    "xmin = -0.5\n",
    "xmax = 13.5\n",
    "\n",
    "# Function parameters:\n",
    "# Binomial:\n",
    "n = 20\n",
    "p = 0.2\n",
    "# Poisson:\n",
    "Lambda = n * p               # We choose this, as this is the expected number of successes.\n",
    "# Gaussian:\n",
    "mu = Lambda                  # Same here - the central value is n*p.\n",
    "sigma = np.sqrt(n*p*(1-p))   # For a Binomial process, the variance is n*p*(1-p)\n",
    "sigma = np.sqrt(n*p)         # Alternatively, one can use the Poisson width.\n",
    "                             # Note how for small values of p, these expressions are essentially the same!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = np.linspace(xmin, xmax, 1000)\n",
    "yaxis_binom = func_binomial_pmf(np.floor(xaxis+0.5), n, p)      # np.floor: See below\n",
    "yaxis_poiss = func_poisson_pmf(np.floor(xaxis+0.5), Lambda)     # np.floor: See below\n",
    "yaxis_gauss = func_gaussian_pdf(xaxis, n*p, np.sqrt(n*p*(1-p)))\n",
    "\n",
    "# Note that the np.floor function takes the integer/rounded (towards zero) value of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0, ax0 = plt.subplots(figsize=(16, 8))\n",
    "ax0.plot(xaxis, yaxis_binom, '-', label=f'Binomial with n={n:2d} and p={p:.3f}')\n",
    "ax0.plot(xaxis, yaxis_poiss, '-', label=f'Poisson with lambda={Lambda:.2f}')\n",
    "ax0.plot(xaxis, yaxis_gauss, '-', label=f'Gaussian with mu={mu:.2f} and sigma={sigma:.2f}')\n",
    "ax0.set(xlim=(xmin, xmax),\n",
    "        title='Probability for Binomial and Gaussian', \n",
    "        xlabel='x', \n",
    "        ylabel='Probability')\n",
    "ax0.set_yscale('log')\n",
    "ax0.set_ylim(1e-4, 1.0)\n",
    "ax0.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping over processes:\n",
    "In the following we simulate a Binomial/Poisson process with given parameters, i.e. number of trials and probability of success. For the Poisson, these can not be specified, but the resulting expected number is naturally lambda = n * p.\n",
    "\n",
    "After having simulated the process, we fit the result with the three distributions in question, and test to what extend they match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters:\n",
    "N_experiments = 1000              # Number of simulations/experiments to perform\n",
    "\n",
    "N_trials = n                      # Number of trials in each experiment (taken from above!)\n",
    "p_success = p                     # Chance of succes in each trial (taken from above!)\n",
    "Lambda = N_trials * p_success     # This is the mean and the one parameter by which the Poisson is defined!\n",
    "\n",
    "print(f\"  With N_trials = {N_trials:d} and p_success = {p_success:.4f}, the average number of successes is lambda = {Lambda:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_n_success = np.zeros(N_experiments)\n",
    "\n",
    "# Run the experiments, and fill the histogram from above:\n",
    "for iexp in range(N_experiments): \n",
    "    \n",
    "    # Simulating process defined:\n",
    "    n_success = 0\n",
    "    for i in range(N_trials): \n",
    "        x = r.uniform()\n",
    "        if (x < p_success): \n",
    "            n_success += 1\n",
    "\n",
    "    # Record result:\n",
    "    if (verbose and iexp < N_verbose): \n",
    "        print(f\"n_success: {n_success:4d}\")\n",
    "        \n",
    "    # Save Result\n",
    "    all_n_success[iexp] = n_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot result:\n",
    "\n",
    "Define a histogram with the \"data\" (note and think about the binning!). Also, ask yourself what uncertainty to assign to each bin?<br>\n",
    "The line of thinking should be: \"There are many possibilities of ending up in a specific bin, but the probability of doing so is each low\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bin_edges = np.histogram(all_n_success, bins=N_trials+1, range=(-0.5, N_trials+0.5))\n",
    "bin_centers = (bin_edges[1:] + bin_edges[:-1])/2\n",
    "s_counts = np.sqrt(counts)                         # NOTE: We (naturally) assume that the bin count is Poisson distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove any bins, which don't have any counts in them (for Chi2 fitting):\n",
    "x = bin_centers[counts>0]\n",
    "y = counts[counts>0]\n",
    "sy = s_counts[counts>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.5, label='Distribution of nSuccesses', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "ax.set(xlim=(xmin, xmax), ylim=(0, 1.2*np.max(y)), xlabel='Number of successes', ylabel='Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting with a Binomial:\n",
    "\n",
    "First define the (fitting) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_binomial(x, N, n, p):\n",
    "    return N * binom.pmf(x, n, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then fit it with a $\\chi^2$-fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Minuit.print_level = 1\n",
    "\n",
    "chi2_bin = Chi2Regression(func_binomial, x, y, sy)\n",
    "chi2_bin.errordef = 1\n",
    "minuit_bin = Minuit(chi2_bin, N=N_experiments, n=N_trials, p=p_success) #   \n",
    "minuit_bin.migrad()          # Perform the actual fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot it on the figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chi2_bin = minuit_bin.fval\n",
    "Ndof_bin = len(x) - 3        # 3 parameters in fit\n",
    "Prob_bin = stats.chi2.sf(Chi2_bin, Ndof_bin)\n",
    "\n",
    "xaxis = np.linspace(-0.5, N_trials+0.5, 1000)                  # This way we include all possibilties!\n",
    "yaxis = func_binomial(np.floor(xaxis+0.5), *minuit_bin.values[:])\n",
    "ax.plot(xaxis, yaxis, '-', label=f'Binomial fit: p(Chi2={Chi2_bin:.1f},Ndof={Ndof_bin:d}) = {Prob_bin:.3f}')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting with a Poisson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_poisson(x, N, mu) :\n",
    "    return N * poisson.pmf(x, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_poisson = Chi2Regression(func_poisson, x, y, sy)\n",
    "chi2_poisson.errordef = 1\n",
    "minuit_poisson = Minuit(chi2_poisson, N=N_experiments, mu=Lambda) #   \n",
    "minuit_poisson.migrad();           # Perform the actual fit (without printing)\n",
    "Chi2_poi = minuit_poisson.fval\n",
    "Ndof_poi = len(x) - 2              # 2 parameters in fit\n",
    "Prob_poi = stats.chi2.sf(Chi2_poi, Ndof_poi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaxis = func_poisson(np.floor(xaxis+0.5), *minuit_poisson.values[:])\n",
    "ax.plot(xaxis, yaxis, '-', label=f'Poisson fit: p(Chi2={Chi2_poi:.1f},Ndof={Ndof_poi:d}) = {Prob_poi:.3f}')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting with a Gaussian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_gaussian(x, N, mu, sigma) :\n",
    "    return N * norm.pdf(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_gaussian = Chi2Regression(func_gaussian, x, y, sy)\n",
    "chi2_gaussian.errordef = 1\n",
    "minuit_gaussian = Minuit(chi2_gaussian, N=N_experiments, mu=Lambda, sigma=np.sqrt(Lambda)) #   \n",
    "minuit_gaussian.migrad();       # Perform the actual fit\n",
    "Chi2_gau = minuit_gaussian.fval\n",
    "Ndof_gau = len(x) - 3           # 3 parameters in fit\n",
    "Prob_gau = stats.chi2.sf(Chi2_gau, Ndof_gau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaxis = func_gaussian(xaxis, *minuit_gaussian.values[:])\n",
    "ax.plot(xaxis, yaxis, '-', label=f'Gaussian fit: p(Chi2={Chi2_gau:.1f},Ndof={Ndof_gau:d}) = {Prob_gau:.3f}')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if save_plots: \n",
    "    fig.savefig(\"BinomialPoissonGaussian.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Binomial $\\chi^2$-value:\n",
    "\n",
    "In this part of the exercise, you are asked to calculate the ChiSquare value yourself, in order to ensure that you understand exactly what is going on!\n",
    "\n",
    "Above, we have (using Minuit) *fitted* the distribution, but as we know the initial values, I would like you to calculate the $\\chi^2$-value between the data and the binomial they were generated from, i.e. with NO free parameters.\n",
    "\n",
    "I suggest you use Pearson's $\\chi^2$, and require `N_obs` and/or `N_exp` > e.g. 0.1. Remember that your choice should ensure, that there is no division by zero (which is a cardinal sin in programming)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bins = len(x)                # Just to know how many bins to loop over\n",
    "chi2_bino = 0.0                # This you'll add to\n",
    "N_dof = 0                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N_obs, x_i in zip(y, x):\n",
    "    N_exp = func_binomial(x_i, N_experiments, N_trials, p_success)\n",
    "    if (N_obs > 0) :\n",
    "        chi2_bino += 0.0       # Write the expression yourself!\n",
    "\n",
    "# Also calculate Ndof and Prob:\n",
    "Ndof_bino = 1                  # Think about/write the number of degrees of freedom given no free parameters!\n",
    "Prob_bino = stats.chi2.sf(chi2_bino, Ndof_bino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(f\"Just a test printout, change to match your own results! \\n\")\n",
    "print(f\"Binomial:   chi2 = {9999:.2f}   N_dof = {9999:d}   Prob = {9999:6.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "\n",
    "More solution code can be found below questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndof_bino = 0\n",
    "for N_obs, x_i in zip(y, x):\n",
    "    N_exp = func_binomial(x_i, N_experiments, N_trials, p_success)\n",
    "    if (N_obs > 0) :\n",
    "        chi2_bino += (N_obs-N_exp)**2 / N_obs\n",
    "        Ndof_bino += 1         # We simply count the number of DoF (nothing to be subtracted given no parameters)\n",
    "\n",
    "# Also calculate Ndof and Prob:\n",
    "Prob_bino = stats.chi2.sf(chi2_bino, Ndof_bino)\n",
    "print(f\"Binomial:   chi2 = {chi2_bino:.2f}   N_dof = {Ndof_bino:d}   Prob = {Prob_bino:6.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "\n",
    "# Questions:\n",
    "\n",
    "Important: Make sure you understand what process yields a Binomial, a Poisson and a Gaussian distribution. Without this knowledge, this exercise and a large fraction of the course will be lost on you!\n",
    "\n",
    "1. Plot a Binomial ($N=20$, $p=0.2$), Poisson ($\\lambda = 4$), and Gaussian ($\\mu=4$, $\\sigma=\\sqrt{4}$), i.e. same means and widths. Which distribution has the longest tail towards high values? And which one has the longest tail the other way? Does this pattern depend on the parameters (given same means and widths)? Play around with the settings (remember also to change the scale (use log) of the plot accordingly), and gain your own experience. And most importantly perhaps, in what limits do they start looking like each other?\n",
    "\n",
    "Example solution 1:\n",
    "The Poisson has the longest tail towards high values, while the Gaussian has the longest tail towards low values, and it is the only distribution with a tail going below 0. This is quite general, but as N becomes large and p small, the Binomial converges towards the Poisson. The two converges towards the Gaussian, when $\\lambda = Np$ becomes large.\n",
    "\n",
    "---\n",
    "\n",
    "2. Producing binomially distributed numbers (using `N_experiments=1000`, `N_trials=10` and `p_success=0.2`), do $\\chi^2$ fits of the resulting distribution with a Binomial, a Poisson, and a Gaussian distribution. Do you get acceptable fit probabilities with all of these? If not, investigate in what cases you do.\n",
    "\n",
    "Example solution 2:\n",
    "The fits try to adjust to the distribution given, but like above (cell 27), the Gaussian only barely manages, while the Poisson (which also only has one single parameter) does not manage. With increasing statistics (i.e. 10000 \"experiments\" and thus entries in the histogram) the Gaussian will also fail to match the data with reasonable p-value. However, increasing $Np$ improves the Gaussian match.\n",
    "\n",
    "---\n",
    "\n",
    "3. Calculate the $\\chi^2$ between the data and the original Binomial distribution (which the data is generated from). Since you are not fitting anything, what is the number of degrees of freedom? Does it give a reasonable $\\chi^2$-probability?\n",
    "\n",
    "Example solution 3:\n",
    "This is mostly an exercise in writing the code behind the ChiSquare calculation, ensuring you know how it is calculated. It also forces you to think about what uncertainty/number you divide the \"observed - expected\" difference with, and how to ensure that this is not 0.\n",
    "In this case, the number of degrees of freedom is the number of bins fitted, as there are zero parameters in the fit! And it should of course give a reasonable $\\chi^2$-probability (p-value) by construction, when matching to a Binomial.\n",
    "\n",
    "---\n",
    "\n",
    "4. In all of the above $\\chi^2$ fits, we have _assumed_ that the uncertainty on the count in each bin is Gaussianly distributed! Ask yourself to what extend this requirement is fulfilled? Does changing the parameters (`N_experiments`, `N_trials` and `p_success`) \"help\" fulfilling this requirement, and if so, which and how?\n",
    "\n",
    "Example solution 4: The Gaussianly assumed distribution of the bin count uncertainty depends on the number of entries in the bin, as the Poisson converges towards the Gaussian with increasing entries. So increasing `N_experiments` helps, while increasing `N_trials` and `p_success` (essentially $\\lambda$) makes the distribution wider, and thus yields fewer events in each bin (assuming equidistant binnning), which in turn means that the Gaussian assumpion worsens.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Advanced questions:\n",
    "\n",
    "5. Using `N_experiments=1000`, `N_trials=1000` and `p_success=1/60`, is the skewness consistent with zero (as the Gaussian should have)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Solution code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = 0\n",
    "xmax = 14\n",
    "x = np.arange(xmin, xmax+1, 1,)\n",
    "n1 = 2000\n",
    "p1 = 0.001\n",
    "lambda1 = n1 * p1\n",
    "sigma1 = np.sqrt(n1* p1*(1-p1))   # For a Binomial process, the variance is n*p*(1-p)\n",
    "sigma1 = np.sqrt(n1*p1)         # Alternatively, one can use the Poisson width \n",
    "\n",
    "binom_1 = func_binomial_pmf(x, n1, p1)\n",
    "pois_1 = func_poisson_pmf(x, lambda1)\n",
    "gaus_1 = func_gaussian_pdf(x, lambda1, sigma1) \n",
    "bi_label = \"binominal p, n = \"+f'{p1, n1}'\n",
    "pois_label = r\"poisson $\\lambda$ = \"+f'{lambda1}'\n",
    "gaus_label = r\"gauss $\\mu, \\; \\sigma$ = \"+f'{lambda1, sigma1}'\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "plt.step(x, binom_1, where='mid', label=bi_label)\n",
    "plt.step(x, pois_1, where='mid', label=pois_label)\n",
    "plt.plot(x, gaus_1, label=gaus_label)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.xlim(xmin, xmax)\n",
    "ax0.set_ylim(1e-4, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 200000\n",
    "p1 = 0.005\n",
    "\n",
    "lambda1 = n1 * p1\n",
    "sigma1 = np.sqrt(n1* p1*(1-p1))   # For a Binomial process, the variance is n*p*(1-p)\n",
    "sigma1 = np.sqrt(n1*p1)         # Alternatively, one can use the Poisson width \n",
    "xmin = lambda1*0.75\n",
    "xmax = lambda1*1.25\n",
    "x = np.arange(xmin, xmax+1, 1,)\n",
    "\n",
    "binom_1 = func_binomial_pmf(x, n1, p1)\n",
    "pois_1 = func_poisson_pmf(x, lambda1)\n",
    "gaus_1 = func_gaussian_pdf(x, lambda1, sigma1) \n",
    "bi_label = \"binominal p, n = \"+f'{p1, n1}'\n",
    "pois_label = r\"poisson $\\lambda$ = \"+f'{lambda1}'\n",
    "gaus_label = r\"gauss $\\mu, \\; \\sigma$ = \"+f'{lambda1, round(sigma1,3)}'\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "plt.step(x, binom_1, where='mid', label=bi_label)\n",
    "plt.step(x, pois_1, where='mid', label=pois_label)\n",
    "plt.plot(x, gaus_1, label=gaus_label)\n",
    "plt.legend()\n",
    "#plt.yscale('log')\n",
    "plt.xlim(xmin, xmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_experiments = 1000             # Number of simulations/experiments to perform\n",
    "N_trials = 20                      # Number of trials in each experiment (taken from above!)\n",
    "p_success = 0.2                     # Chance of succes in each trial (taken from above!)\n",
    "Lambda = N_trials * p_success \n",
    "sigma1 = np.sqrt(N_trials* p1*(1-p1))   # For a Binomial process, the variance is n*p*(1-p)\n",
    "sigma1 = np.sqrt(n1*p1)         # Alternatively, one can use the Poisson width \n",
    "\n",
    "all_n_success = [sum(np.random.uniform(0, 1, N_trials) < p_success) for i in range(N_experiments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "count, bins, ignored = plt.hist(all_n_success, max(all_n_success), alpha=0.2)\n",
    "mid_bins = 0.5*(bins[1:]+bins[:-1])\n",
    "\n",
    "Ndof_binom1 = len(count) - 3\n",
    "Ndof_pois1 = len(count) - 2\n",
    "Ndof_gaus1 = len(count) - 3\n",
    "\n",
    "sigma_counts = np.sqrt(count) #sigma assumed from Poisson \n",
    "\n",
    "binom_1, binom_1_err = curve_fit(func_binomial, mid_bins-0.5, count, p0=[N_experiments, N_trials,p_success])\n",
    "y_binom = func_binomial(mid_bins-0.5, *binom_1)\n",
    "chi_binom = np.sum((count - y_binom)**2 / y_binom)\n",
    "chi_binom_p = stats.chi2.sf(chi_binom, Ndof_binom1)\n",
    "chi_binom_l = r\"$\\chi^2$, p-value = \" + f'{round(chi_binom,2), round(chi_binom_p,3)}'\n",
    "\n",
    "pois_1, pois_1_err = curve_fit(func_poisson, mid_bins-0.5, count, p0=[N_experiments, Lambda])\n",
    "y_pois = func_poisson(mid_bins-0.5, *pois_1)\n",
    "chi_pois = np.sum((count - y_pois)**2 / y_pois)\n",
    "chi_pois_p = stats.chi2.sf(chi_pois, Ndof_pois1)\n",
    "chi_pois_l = r\"$\\chi^2$, p-value = \" + f'{round(chi_pois,2), round(chi_pois_p,3)}'\n",
    "\n",
    "gaus_1, gaus_1_err = curve_fit(func_gaussian, mid_bins-0.5, count, p0=[N_experiments, Lambda, sigma1])\n",
    "y_gaus = func_gaussian(mid_bins-0.5, *gaus_1)\n",
    "chi_gaus = np.sum((count - y_gaus)**2 / y_gaus)\n",
    "chi_gaus_p = stats.chi2.sf(chi_gaus, Ndof_gaus1)\n",
    "chi_gaus_l = r\"$\\chi^2$, p-value = \" + f'{round(chi_gaus,2), round(chi_gaus_p,3)}'\n",
    "\n",
    "plt.errorbar(mid_bins, count, yerr=sigma_counts, xerr=0.5, label='Distribution of n-Successes', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "\n",
    "plt.step(mid_bins, y_binom, where='mid', label=chi_binom_l)\n",
    "plt.step(mid_bins, y_pois, where='mid', label=chi_pois_l)\n",
    "plt.step(mid_bins, y_gaus, where='mid', label=chi_gaus_l)\n",
    "plt.xlim(0, np.max(bins)+2)\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_experiments = 1000             \n",
    "N_trials = 1000                      \n",
    "p_success = 1./60\n",
    "\n",
    "all_n_success = [sum(np.random.uniform(0, 1, N_trials) < p_success) for i in range(N_experiments)]\n",
    "\n",
    "skew = stats.skew(all_n_success)\n",
    "sigma_skew = np.sqrt(6 * N_experiments * (N_experiments-1) / (N_experiments-2) / (N_experiments+1) / (N_experiments+3))\n",
    "print(skew, sigma_skew, skew/sigma_skew)"
   ]
  }
 ],
 "metadata": {
  "executable": "/usr/bin/env python",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "main_language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
